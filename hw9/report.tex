\documentclass[10pt]{article}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{natbib}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{amssymb} 

\renewcommand{\P}{\mathbb{P}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\E}{\mathrm{E}}
\newcommand{\Var}{\mathrm{Var}}

\title{MCMT Homework 9}
\author{Shun Zhang}
\date{}

\begin{document}
\maketitle

\section*{Exercise 9.1}

Let $Y_t$ denote the number of coordinates that have been selected after $t$ rounds.
Define the distinguishing statistic $f:\{0,1\}^n \rightarrow R$ by
$f(x)=\sum_{i=1}^n x_i$.

\begin{enumerate}

%1.
\item The probability that one coordinate is not selected in $t$ steps is $p = (1 -
\frac{1}{n})^t$. The expectation of the number of coordinates that are not
selected in $t$ steps is $\E(n - Y_t) = np = n(1 - \frac{1}{n})^t$. So $\E(Y_t) =
n - n(1 - \frac{1}{n})^t$.

%2.
\item Let $I_i(t)$ be the indicator that $i$-th coordinate has been selected at
$t$-th step.

$\E(I_i(t) I_j(t)) = 2(1 - (1 - \frac{1}{n})^t) - (1 - (1 - \frac{2}{n})^t) = 1
- 2(1 - \frac{1}{n})^t + (1 - \frac{2}{n})^t$.

$\E(I_i(t))\E(I_j(t)) = (1 - (1 - \frac{1}{n})^t)^2$.

$\Cov(I_i(t), I_j(t)) = \E(I_i(t) I_j(t)) - \E(I_i(t))\E(I_j(t)) = (1 -
\frac{2}{n})^t - (1 - \frac{1}{n})^{2t} \leq 0$.

$\Var(Y_t) = \Var(\sum_i I_i(t)) = \sum_i(\Var (I_i(t))) + \sum_{i \neq
j}\Cov(I_i(t), I_j(t)) \leq \sum_i(\Var (I_i(t))) \leq n p(1-p) \leq \frac{n}{4}$.

%3.
\item $\E_0(X_{ti} | Y_t) = \frac{Y_t}{n} \frac{1}{2}$. This is the probability
that $x_i$ is chosen, and times the probability that it is set to be 1.

$\E_0(f(X_t) | Y_t) = \sum_i \E_0(X_{ti} | Y_t) = \frac{Y_t}{2}$.

$\E_0(f(X_t)) = \sum_y \E_0(f(X_t) | Y_t = y) P(Y_t = y) = \sum_y \frac{y}{2}
P(Y_t = y) = \frac{\E(Y_t)}{2}$.

%4.
\item
$\Var_0(f(X_t) | Y_t) = Y_t \frac{1}{2} (1 - \frac{1}{2}) = \frac{1}{4} Y_t$, as
$f(X_t)$ given $Y_t$ is a Binomial distribution.
$\E_0 \Var_0(f(X_t) | Y_t) = \frac{1}{4} \E_0(Y_t)$.

$\E_0(f(X_t) | Y_t) = \frac{Y_t}{2}$.
$\Var_0 \E_0(f(X_t) | Y_t) = \Var_0 \frac{Y_t}{2} = \frac{1}{4} \Var_0 (Y_t)$.

$\Var_0(f(X_t)) = \E_0 \Var_0(f(X_t) | Y_t) + \Var_0 (\E_0(f(X_t) | Y_t)) =
\frac{1}{4} (\E (Y_t) + \Var (Y_t))$.

By substituting by the results we have,
$\E (Y_t) + \Var (Y_t)
= n - n(1 - \frac{1}{n})^t + (n^2 - n) cov + n (1 - \frac{1}{n})^t (1 - (1 -
\frac{1}{n})^t)
= n + (n^2 - n) cov - n (1 - \frac{1}{n})^t
< n
$
, where $cov$ is $\Cov(I_i(t), I_j(t))$ for $i \neq j$, which we have shown to
be negative.

So, $\Var_0(f(X_t)) < \frac{1}{4} n$.

%5.
\item $f$ on $\pi$ is a Binomial distribution. So $E_\pi f = \frac{n}{2}$,
$\Var_\pi f = n \frac{1}{2} (1 - \frac{1}{2}) = \frac{n}{4}$.

%6.
\item Consider two distributions $P^t(0, \cdot)$ and $\pi$.

$\sigma^2 \leq (\frac{n}{4} + \frac{n}{4}) / 2 = \frac{n}{4}$.

$\Delta = |\frac{EY_t}{2} - \frac{n}{2}| = \dfrac{n - EY_t}{2} =
\dfrac{n(1-\frac{1}{n})^t}{2}$.

By Lemma 9.7, 
$||P^t(0, \cdot) - \pi||_{TV}
\geq \dfrac{\Delta^2}{4 \sigma^2 + \Delta^2}
= 1 - \dfrac{4 \sigma^2}{4 \sigma^2 + \Delta^2}
\geq 1 - \dfrac{n}{n + \frac{n^2(1-\frac{1}{n})^{2t}}{4}}
= 1 - 8 \dfrac{1}{8 + 2n(1-\frac{1}{n})^{2t}}
= 1 - 8 \exp\{-\log(8 + 2n(1-\frac{1}{n})^{2t})\}
$

We know $d(t) \geq ||P^t(0, \cdot) - \pi||_{TV}$. Let $t =
\frac{1}{2}n\log n - cn$.

$d(\frac{1}{2}n\log n - cn)
\geq 1 - 8 \exp\{-\log(8 + 2n(1-\frac{1}{n})^{n\log n - 2cn})\}\\
\geq 1 - 8 \exp\{- 2c + 1\}
$

\end{enumerate}

\end{document}
